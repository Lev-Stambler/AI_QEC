{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stable_baselines3[extra] -q\n",
    "# !pip install pyglet==1.5.27 -q\n",
    "# !pip install -U bposd -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the common library for CPC codes\n",
    "import os\n",
    "import sys\n",
    "# TODO: lets do something better here like refactor the common parts and different learning mech parts\n",
    "!export PATH=$PATH:~/.local/bin\n",
    "sys.path.append(os.getcwd() + \"/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: /home/lev/.local/share/aff3ct/build/bin/aff3ct-3.0.2 -C <text> [optional args...]\n",
      "\n",
      "\u001b[1m\u001b[3m\u001b[35mSimulation parameter(s):\u001b[0m\n",
      "\u001b[1m\u001b[31m{R} \u001b[0m\u001b[1m--sim-cde-type, -C\u001b[0m\u001b[37m <text:including set={BCH|LDPC|POLAR|POLAR_MK|RA|REP|RS|RSC|RSC_DB|TPC|TURBO|TURBO_DB|UNCODED}>\u001b[0m\n",
      "      Select the channel code family to simulate. \n",
      "    \u001b[1m--sim-prec, -p    \u001b[0m\u001b[37m <integer:including set={8|16|32|64}>\u001b[0m\n",
      "      Specify the representation of the real numbers in the receiver part of the \n",
      "      chain. \n",
      "    \u001b[1m--sim-type        \u001b[0m\u001b[37m <text:including set={BFER|BFERI}>\u001b[0m\n",
      "      Select the type of simulation (or communication chain skeleton). \n",
      "\n",
      "\u001b[1m\u001b[3m\u001b[35mOther parameter(s):\u001b[0m\n",
      "    \u001b[1m--Help, -H        \u001b[0m\n",
      "      Print the help like with the '--help, -h' parameter plus advanced \n",
      "      arguments (denoted as '{A}'). \n",
      "    \u001b[1m--help, -h        \u001b[0m\n",
      "      Print the help with all the required (denoted as '{R}') and optional \n",
      "      arguments. The latter change depending on the selected simulation type and \n",
      "      code. \n",
      "    \u001b[1m--no-colors       \u001b[0m\n",
      "      Disable the colors in the shell. \n",
      "    \u001b[1m--version, -v     \u001b[0m\n",
      "      Print informations about the version of the source code and compilation \n",
      "      options. \n",
      "\n",
      "\u001b[1m\u001b[31m(EE) \u001b[0mThe \"--sim-cde-type, -C\" argument is required.\n"
     ]
    }
   ],
   "source": [
    "# !aff3ct\n",
    "!aff3ct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the RL Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "from global_params import params\n",
    "from scoring import score_dataset\n",
    "from CPC import cpc_code, generate_random as gen_random_cpc\n",
    "\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Some quick thoughts:\n",
    "-- Should we start with a specific code each time or always a new random code?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SwapLDPCEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "\n",
    "    def __init__(self, target_succ_rate=0.99):\n",
    "        super(SwapLDPCEnv, self).__init__()\n",
    "\n",
    "        self.target_succ_rate = target_succ_rate\n",
    "        _, m_b, m_p, m_c = gen_random_cpc.random_cpc()\n",
    "        self.m_b = m_b\n",
    "        self.m_p = m_p\n",
    "        self.m_c = m_c\n",
    "        self.original_m_b = copy.deepcopy(m_b)\n",
    "        self.original_m_p = copy.deepcopy(m_p)\n",
    "        self.original_m_c = copy.deepcopy(m_c)\n",
    "\n",
    "        # self.target_succ_rate = target_succ_rate\n",
    "        # Each action corresponds to choosing to parity checks and the corresponding edges to swap\n",
    "        self.action_space = spaces.MultiDiscrete([\n",
    "            3,  # select which matrix to operate on, m_b, m_p, or m_c\n",
    "            # select which parity check to operate on\n",
    "            params['n_data_qubits'],\n",
    "            # higher than the check qubit index return a low reward\n",
    "            params['n_check_qubits'],\n",
    "            # select which data qubit to operate on. If m_c is selected, have choosing a data qubit\n",
    "        ])\n",
    "        self.last_fer = 0\n",
    "        self.n_steps = 0\n",
    "        self.current_run_len = 0\n",
    "\n",
    "        self.n_qubits = n_qubits = (params['n_data_qubits'] +\n",
    "                                    params['n_check_qubits']) * 2\n",
    "\n",
    "        # The first n qubits represent the noise distribution\n",
    "        # TODO: THIS ALLOWS US TO TRAIN FOR \"ADAPTIVE NOISE!!\" (i.e. lets decrease connections...)\n",
    "        # The quantum parity check matrix\n",
    "        self.observation_space = spaces.Box(low=0, high=1,\n",
    "                                            shape=(params['n_check_qubits'], n_qubits), dtype=np.uint8)\n",
    "        code_pc = cpc_code.get_classical_code_cpc(self.m_b, self.m_p, self.m_c)\n",
    "        p_fails = np.ones(self.n_qubits) * np.random.uniform(\n",
    "            low=params['constant_error_rate_lower'], high=params['constant_error_rate_upper'])\n",
    "        self.last_wsr = score_dataset.run_decoder(code_pc, p_fails)\n",
    "\n",
    "        # TODO: WHAT NUMBER???\n",
    "        self.max_run_len = 150\n",
    "        self.reward_step = 0.008\n",
    "\n",
    "    def step(self, action):\n",
    "        p_fails = np.ones(self.n_qubits) * np.random.uniform(\n",
    "            low=params['constant_error_rate_lower'], high=params['constant_error_rate_upper'])\n",
    "        if action[0] == 0:\n",
    "            self.m_b[action[1], action[2]] = 1 - self.m_b[action[1], action[2]]\n",
    "        elif action[0] == 1:\n",
    "            self.m_p[action[1], action[2]] = 1 - self.m_p[action[1], action[2]]\n",
    "        elif action[0] == 2:\n",
    "            if action[1] >= params['n_check_qubits']:\n",
    "                old_code_pc = cpc_code.get_classical_code_cpc(\n",
    "                    self.m_b, self.m_p, self.m_c)\n",
    "                obs = old_code_pc\n",
    "                return obs, -1, False, {}  # Return a very low reward\n",
    "            self.m_c[action[1], action[2]] = 1 - self.m_c[action[1], action[2]]\n",
    "        else:\n",
    "            raise \"Undefined selector action\"\n",
    "\n",
    "        code_pc = cpc_code.get_classical_code_cpc(self.m_b, self.m_p, self.m_c)\n",
    "        # TODO: p_fail??\n",
    "        succ_rate = score_dataset.run_decoder(code_pc, p_fails)\n",
    "\n",
    "        self.last_fer = 1 - succ_rate\n",
    "\n",
    "        # TODO: scaling?\n",
    "        reward = 1 if succ_rate > self.last_wsr + self.reward_step else 0\n",
    "        self.last_wsr = succ_rate\n",
    "        obs = code_pc\n",
    "\n",
    "        # Update global parameters\n",
    "        self.n_steps += 1\n",
    "\n",
    "        done = succ_rate >= self.target_succ_rate\n",
    "        if self.current_run_len > self.max_run_len:\n",
    "            done = True\n",
    "            self.current_run_len = 0\n",
    "\n",
    "        self.current_run_len += 1\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.m_b = copy.deepcopy(self.original_m_b)\n",
    "        self.m_p = copy.deepcopy(self.original_m_p)\n",
    "        self.m_c = copy.deepcopy(self.original_m_c)\n",
    "        code_pc = cpc_code.get_classical_code_cpc(self.m_b, self.m_p, self.m_c)\n",
    "        return code_pc\n",
    "\n",
    "    def render(self, mode='console'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "env = SwapLDPCEnv()\n",
    "check_env(env, warn=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "# from stable_baselines3.common import set_random_seed, make_vec_env\n",
    "\n",
    "model_type = \"PPO\"\n",
    "check_env(env, warn=True)\n",
    "tf_logs = \"./logs/{model_type}-tensorboard\"\n",
    "\n",
    "def make_env(rank, seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environments you wish to have in subprocesses\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = SwapLDPCEnv() \n",
    "        env.seed(seed + rank)\n",
    "        return env\n",
    "    # set_global_seeds(seed)\n",
    "    return _init\n",
    "\n",
    "num_cpu = 4\n",
    "\n",
    "# wrap it\n",
    "env = SubprocVecEnv([make_env(i) for i in range(num_cpu)])\n",
    "# make_vec_env(lambda: env,   n_envs=1)\n",
    "\n",
    "loading_saved = False\n",
    "\n",
    "model = None\n",
    "if not loading_saved:\n",
    "\tmodel = PPO(\"MlpPolicy\", env=env, tensorboard_log=tf_logs)\n",
    "else:\n",
    "\t# TODO!\n",
    "\tmodel = PPO.load(utils.get_most_recent_model_path_rl(), env=env, print_system_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup the callbacks\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList, BaseCallback\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting additional values in tensorboard.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        self.is_tb_set = False\n",
    "        super(TensorboardCallback, self).__init__(verbose)\n",
    "        writer = tf.summary.create_file_writer(tf_logs) ## TODO?\n",
    "        self.writer = writer\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Log additional tensor\n",
    "        # if not self.is_tb_set:\n",
    "        #     with self.model.graph.as_default():\n",
    "        #         tf.summary.scalar('value_target', tf.reduce_mean(self.model.value_target))\n",
    "        #         self.model.summary = tf.summary.merge_all()\n",
    "        #     self.is_tb_set = True\n",
    "\n",
    "        # Log scalar value (here a random variable)\n",
    "        fers = self.model.get_env().get_attr(\"last_fer\", list(range(num_cpu)))\n",
    "        fer = sum(fers) / len(fers)\n",
    "        with self.writer.as_default():\n",
    "            n_steps = self.model.get_env().get_attr(\"n_steps\", list(range(num_cpu)))\n",
    "            n_steps_avg = int(sum(n_steps) / len(n_steps))\n",
    "            tf.summary.scalar('Frame Error Rate', fer, step=n_steps_avg)\n",
    "            self.writer.flush()\n",
    "        return True\n",
    "\n",
    "\n",
    "# From https://stable-baselines.readthedocs.io/en/master/guide/examples.html\n",
    "class SaveModelOnTraining(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super(SaveModelOnTraining, self).__init__(verbose)\n",
    "        self.check_freq = params['rl_save_model_freq']\n",
    "        self.save_path = utils.get_most_recent_model_path_rl()\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "          \n",
    "          self.model.save(self.save_path)\n",
    "          print(\"Saving new model to {} for step {}\".format(self.save_path), self.n_calls)\n",
    "          with open(utils.get_most_recent_model_path_rl_info(), 'w') as f:\n",
    "            data = {\n",
    "              \"n_steps\": self.n_calls,\n",
    "              # \"last_fer\": \n",
    "            }\n",
    "            json.dump(data, f)\n",
    "        return True\n",
    "\n",
    "\n",
    "# TODO: save everything else (like approx kl etc. for tensor board logs)\n",
    "callback_list = CallbackList([TensorboardCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=10_000, callback=callback_list)\n",
    "# for i in range(25):\n",
    "# \tmodel.learn(total_timesteps=100_000, callback=callback_list)\n",
    "# \tmodel.save(utils.get_most_recent_model_path_rl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(utils.get_most_recent_model_path_rl())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
