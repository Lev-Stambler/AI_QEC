{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the common library for CPC codes\n",
    "import os\n",
    "import sys\n",
    "# TODO: lets do something better here like refactor the common parts and different learning mech parts\n",
    "!export PATH=$PATH:~/.local/bin\n",
    "sys.path.append(os.getcwd() + \"/../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect RL Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import CPCTrialParams\n",
    "\n",
    "params = CPCTrialParams(n=40, m_x=30, dv_x=3, m_z=30, dv_z=3,\n",
    "                        n_cross_checks=0, p_error=[0.01, 0.0, 0.01], seeds=[0, 1])\n",
    "model_save_path = f\"./models/rl_model_{params.get_key()}\"\n",
    "cpc_original_save_path = f\"./models/original_cpc_{params.get_key()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplifying the input code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lev/.local/lib/python3.10/site-packages/stable_baselines3/common/env_checker.py:130: UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gym\n",
    "from gym import spaces\n",
    "from RL.env import CPCAddCrossEnv\n",
    "from CPC.generate_random import random_cpc\n",
    "from CPC.cpc_code import CPCCode\n",
    "\n",
    "env = CPCAddCrossEnv(params)\n",
    "check_env(env, warn=True)\n",
    "\n",
    "starting_cpc: CPCCode = None\n",
    "if os.path.isfile(cpc_original_save_path):\n",
    "    starting_cpc = CPCCode.load(cpc_original_save_path)\n",
    "else:\n",
    "    starting_cpc = random_cpc(params.n, params.m_x, params.dv_x,\n",
    "                              params.m_z, params.dv_z, params.seeds[0], params.seeds[1])\n",
    "    starting_cpc.save(cpc_original_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = f\"./models/rl_model_{params.get_key()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "OS: Linux-5.19.0-35-generic-x86_64-with-glibc2.35 #36~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Feb 17 15:17:25 UTC 2\n",
      "Python: 3.10.6\n",
      "Stable-Baselines3: 1.6.2\n",
      "PyTorch: 1.13.0+cu117\n",
      "GPU Enabled: False\n",
      "Numpy: 1.23.5\n",
      "Gym: 0.21.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "OS: Linux-5.19.0-35-generic-x86_64-with-glibc2.35 #36~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Feb 17 15:17:25 UTC 2\n",
      "Python: 3.10.6\n",
      "Stable-Baselines3: 1.6.2\n",
      "PyTorch: 1.13.0+cu117\n",
      "GPU Enabled: False\n",
      "Numpy: 1.23.5\n",
      "Gym: 0.21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "# from stable_baselines3.common import set_random_seed, make_vec_env\n",
    "\n",
    "model_type = \"PPO\"\n",
    "check_env(env, warn=True)\n",
    "tf_logs = \"./logs/{model_type}-tensorboard\"\n",
    "\n",
    "def make_env(rank, seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environments you wish to have in subprocesses\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = CPCAddCrossEnv(params, max_cross_edges=175, starting_cpc=starting_cpc) \n",
    "        env.seed(seed + rank)\n",
    "        return env\n",
    "    # set_global_seeds(seed)\n",
    "    return _init\n",
    "\n",
    "num_cpu = 4\n",
    "\n",
    "# wrap it\n",
    "env = SubprocVecEnv([make_env(i) for i in range(num_cpu)])\n",
    "# make_vec_env(lambda: env,   n_envs=1)\n",
    "\n",
    "loading_saved = True\n",
    "\n",
    "model = None\n",
    "if not loading_saved:\n",
    "\tmodel = PPO(\"MlpPolicy\", env=env, tensorboard_log=tf_logs)\n",
    "else:\n",
    "\tmodel = PPO.load(f\"{model_save_path}.zip\", env=env, print_system_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 14:26:43.085115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 14:26:43.758247: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-03-15 14:26:43.758310: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-03-15 14:26:43.758316: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-15 14:26:44.230048: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-03-15 14:26:44.230067: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-15 14:26:44.230085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lev-ThinkPad-P14s-Gen-1): /proc/driver/nvidia/version does not exist\n",
      "2023-03-15 14:26:44.230238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## Setup the callbacks\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList, BaseCallback\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting additional values in tensorboard.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        self.is_tb_set = False\n",
    "        super(TensorboardCallback, self).__init__(verbose)\n",
    "        writer = tf.summary.create_file_writer(tf_logs) ## TODO?\n",
    "        self.writer = writer\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Log additional tensor\n",
    "        # if not self.is_tb_set:\n",
    "        #     with self.model.graph.as_default():\n",
    "        #         tf.summary.scalar('value_target', tf.reduce_mean(self.model.value_target))\n",
    "        #         self.model.summary = tf.summary.merge_all()\n",
    "        #     self.is_tb_set = True\n",
    "\n",
    "        # Log scalar value (here a random variable)\n",
    "        wers = self.model.get_env().get_attr(\"last_wer\", list(range(num_cpu)))\n",
    "        wer = sum(wers) / len(wers)\n",
    "        n_steps = self.model.get_env().get_attr(\"n_steps\", list(range(num_cpu)))\n",
    "        n_steps_avg = int(sum(n_steps) / len(n_steps))\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar('Word Error Rate', wer, step=n_steps_avg)\n",
    "            self.writer.flush()\n",
    "        return True\n",
    "\n",
    "\n",
    "# From https://stable-baselines.readthedocs.io/en/master/guide/examples.html\n",
    "class SaveModelOnTraining(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super(SaveModelOnTraining, self).__init__(verbose)\n",
    "        self.check_freq = 1_000\n",
    "        self.save_path = model_save_path\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "          \n",
    "          self.model.save(self.save_path)\n",
    "          print(\"Saving new model to {} for step {}\".format(self.save_path), self.n_calls)\n",
    "          # with open(utils.get_most_recent_model_path_rl_info(), 'w') as f:\n",
    "          #   data = {\n",
    "          #     \"n_steps\": self.n_calls,\n",
    "          #     # \"last_fer\": \n",
    "          #   }\n",
    "          #   json.dump(data, f)\n",
    "        return True\n",
    "\n",
    "\n",
    "callback_list = CallbackList([TensorboardCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.learn(total_timesteps=40_000, callback=callback_list, reset_num_timesteps=True, eval_freq=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBS (4, 60, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "            0.0100 ||    38324 |     4351 |      978 | 1.42e-03 | 2.55e-02 ||    5.901 | 00h00'00  * *\r"
     ]
    }
   ],
   "source": [
    "from ldpc_classical.aff3ct_wrapper import aff3ct_simulate\n",
    "import common\n",
    "\n",
    "obs = env.reset()\n",
    "print(\"OBS\", obs.shape)\n",
    "\n",
    "for i in range(120):\n",
    "    action, _ = model.predict(obs)\n",
    "    # print(\"AAAA\", action)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    # print(\"R\", nexts)\n",
    "    cpcs: list[CPCCode] = env.get_attr(\"cpc\", list(range(num_cpu)))\n",
    "    if True in done:\n",
    "        for i, d in enumerate(done):\n",
    "            if d:\n",
    "                H, bittypes = cpcs[i].get_tanner_graph()\n",
    "                wer = aff3ct_simulate.get_wer(obs[i], common.calculate_tanner_p_error_depolarizing(bittypes, params.p_error[0],\n",
    "                                                                                                   params.p_error[1],\n",
    "                                                                                                   params.p_error[2]))\n",
    "                print(f\"For code index {i}, error of {wer}\")\n",
    "    if done.all():\n",
    "        print(\"R Done\", reward)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 0 1 ... 0 0 1]\n",
      "  [0 0 0 ... 0 1 0]\n",
      "  [0 0 1 ... 1 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 1 0 ... 0 0 0]]\n",
      "\n",
      " [[1 0 1 ... 0 0 1]\n",
      "  [0 0 0 ... 0 1 0]\n",
      "  [0 0 1 ... 1 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 1 0 ... 0 0 0]]\n",
      "\n",
      " [[1 0 1 ... 0 0 1]\n",
      "  [0 0 0 ... 0 1 0]\n",
      "  [0 0 1 ... 1 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 1 0 ... 0 0 0]]\n",
      "\n",
      " [[1 0 1 ... 0 0 1]\n",
      "  [0 0 0 ... 0 1 0]\n",
      "  [0 0 1 ... 1 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 1]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 1 0 ... 1 0 0]]]\n",
      "For code index 3, error of 0.02959999999999996\n"
     ]
    }
   ],
   "source": [
    "print(obs)\n",
    "cpcs: list[CPCCode] = env.get_attr(\"cpc\", list(range(num_cpu)))\n",
    "i = 3\n",
    "H, bittypes = cpcs[i].get_tanner_graph()\n",
    "wer = aff3ct_simulate.get_wer(obs[i], common.calculate_tanner_p_error_depolarizing(bittypes, params.p_error[0],\n",
    "                                                                                   params.p_error[1],\n",
    "                                                                                   params.p_error[2]))\n",
    "print(f\"For code index {i}, error of {wer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
