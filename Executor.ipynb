{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install livelossplot -q\n",
    "# !pip install bposd -q\n",
    "# !pip install json -q\n",
    "# !pip install multiprocessing -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"epoch_0\": {\"p_0.015\": 0.65472, \"low_p_best_0.001\": 0.99834, \"low_p_best_0.005\": 0.96988, \"low_p_best_0.01\": 0.88608, \"low_p_best_0.015\": 0.81122}}"
     ]
    }
   ],
   "source": [
    "!cat results.json || echo '{}' >> results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import matplotlib_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + \"/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lev/code/research/ai/AI_QEC/src/scoring/score_dataset.py:52: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(n_runs // block_size == n_runs / block_size, \"Number of runs must be multiple of block size\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to evaluate performance for epoch 0\n",
      "Done evaluating performance for epoch 0\n",
      "Starting epoch #1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Caught AssertionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/lev/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/lev/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/lev/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/lev/code/research/ai/AI_QEC/src/scoring/score_dataset.py\", line 80, in __getitem__\n    error_rate = self.calculate_error_rate(cpc_code_pc, e)\n  File \"/home/lev/code/research/ai/AI_QEC/src/scoring/score_dataset.py\", line 87, in calculate_error_rate\n    return run_decoder(code, self.item_sample_size, error_prob) / self.item_sample_size\n  File \"/home/lev/code/research/ai/AI_QEC/src/scoring/score_dataset.py\", line 56, in run_decoder\n    with Pool() as pool:\n  File \"/usr/lib/python3.10/multiprocessing/context.py\", line 119, in Pool\n    return Pool(processes, initializer, initargs, maxtasksperchild,\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 215, in __init__\n    self._repopulate_pool()\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 306, in _repopulate_pool\n    return self._repopulate_pool_static(self._ctx, self.Process,\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 329, in _repopulate_pool_static\n    w.start()\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 118, in start\n    assert not _current_process._config.get('daemon'), \\\nAssertionError: daemonic processes are not allowed to have children\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m main\n\u001b[1;32m      2\u001b[0m loss_plt \u001b[39m=\u001b[39m PlotLosses()\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m main(loss_plt, load_saved_scoring_model\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, skip_testing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/code/research/ai/AI_QEC/src/training.py:109\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(plot_loss, load_saved_scoring_model, load_saved_generating_model, skip_testing)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarting epoch #\u001b[39m\u001b[39m{\u001b[39;00mgenetic_epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m scoring_copied \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(scoring_model)\n\u001b[0;32m--> 109\u001b[0m train_score_model_with_generator(\n\u001b[1;32m    110\u001b[0m     scoring_model, scoring_copied, generating_model, plot_loss, skip_testing\u001b[39m=\u001b[39;49mskip_testing)\n\u001b[1;32m    111\u001b[0m \u001b[39mdel\u001b[39;00m scoring_copied\n\u001b[1;32m    112\u001b[0m \u001b[39m# TODO: make p_range better\u001b[39;00m\n",
      "File \u001b[0;32m~/code/research/ai/AI_QEC/src/training.py:77\u001b[0m, in \u001b[0;36mtrain_score_model_with_generator\u001b[0;34m(scoring_model, scoring_model_copy, generating_model, plot_loss, skip_testing)\u001b[0m\n\u001b[1;32m     74\u001b[0m err \u001b[39m=\u001b[39m ge()\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgc\u001b[39m(): \u001b[39mreturn\u001b[39;00m generating_model\u001b[39m.\u001b[39mgenerate_sample(scoring_model_copy, err)\n\u001b[0;32m---> 77\u001b[0m scoring\u001b[39m.\u001b[39;49mscore_training\u001b[39m.\u001b[39;49mmain_training_loop(\n\u001b[1;32m     78\u001b[0m     scoring_model, ge, gc, params[\u001b[39m'\u001b[39;49m\u001b[39mscoring_model_save_path\u001b[39;49m\u001b[39m'\u001b[39;49m], params[\u001b[39m'\u001b[39;49m\u001b[39mn_score_training_per_epoch_genetic\u001b[39;49m\u001b[39m'\u001b[39;49m],  plot_loss, skip_testing\u001b[39m=\u001b[39;49mskip_testing)\n",
      "File \u001b[0;32m~/code/research/ai/AI_QEC/src/scoring/score_training.py:136\u001b[0m, in \u001b[0;36mmain_training_loop\u001b[0;34m(model, error_prob_sample, random_code_sample, save_path, n_score_training_samples, plot_loss, skip_testing)\u001b[0m\n\u001b[1;32m    134\u001b[0m best_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 136\u001b[0m     loss \u001b[39m=\u001b[39m train(model, device, train_dataloader, optimizer,\n\u001b[1;32m    137\u001b[0m                  epoch, LR\u001b[39m=\u001b[39;49mscheduler\u001b[39m.\u001b[39;49mget_last_lr()[\u001b[39m0\u001b[39;49m], plot_loss\u001b[39m=\u001b[39;49mplot_loss)\n\u001b[1;32m    138\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStepping with scheduler\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/code/research/ai/AI_QEC/src/scoring/score_training.py:31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, LR, plot_loss, plotting_period)\u001b[0m\n\u001b[1;32m     29\u001b[0m train_std_dev \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     30\u001b[0m past_preds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (bit_adj, phase_adj, check_adj, error_distr, error_rate) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m     32\u001b[0m         train_loader):\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m cum_samples \u001b[39m%\u001b[39m plotting_period \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     34\u001b[0m         \u001b[39mif\u001b[39;00m cum_samples \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1360\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAssertionError\u001b[0m: Caught AssertionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/lev/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/lev/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/lev/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/lev/code/research/ai/AI_QEC/src/scoring/score_dataset.py\", line 80, in __getitem__\n    error_rate = self.calculate_error_rate(cpc_code_pc, e)\n  File \"/home/lev/code/research/ai/AI_QEC/src/scoring/score_dataset.py\", line 87, in calculate_error_rate\n    return run_decoder(code, self.item_sample_size, error_prob) / self.item_sample_size\n  File \"/home/lev/code/research/ai/AI_QEC/src/scoring/score_dataset.py\", line 56, in run_decoder\n    with Pool() as pool:\n  File \"/usr/lib/python3.10/multiprocessing/context.py\", line 119, in Pool\n    return Pool(processes, initializer, initargs, maxtasksperchild,\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 215, in __init__\n    self._repopulate_pool()\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 306, in _repopulate_pool\n    return self._repopulate_pool_static(self._ctx, self.Process,\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 329, in _repopulate_pool_static\n    w.start()\n  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 118, in start\n    assert not _current_process._config.get('daemon'), \\\nAssertionError: daemonic processes are not allowed to have children\n"
     ]
    }
   ],
   "source": [
    "from training import main\n",
    "loss_plt = PlotLosses()\n",
    "model = main(loss_plt, load_saved_scoring_model=True, skip_testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15262/20000: 0.7631\n"
     ]
    }
   ],
   "source": [
    "import code_evaluation\n",
    "import numpy as np\n",
    "from global_params import params\n",
    "\n",
    "e = np.ones(((params['n_data_qubits'] + params['n_check_qubits']) * 2)) * 0.01\n",
    "code_evaluation.main(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
