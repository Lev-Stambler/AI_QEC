{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stable_baselines3[extra] -q\n",
    "# !pip install pyglet==1.5.27 -q\n",
    "# !pip install -U bposd -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the common library for CPC codes\n",
    "import os\n",
    "import sys\n",
    "# TODO: lets do something better here like refactor the common parts and different learning mech parts\n",
    "!export PATH=$PATH:~/.local/bin\n",
    "sys.path.append(os.getcwd() + \"/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: /home/lev/.local/share/aff3ct/build/bin/aff3ct-3.0.2 -C <text> [optional args...]\n",
      "\n",
      "\u001b[1m\u001b[3m\u001b[35mSimulation parameter(s):\u001b[0m\n",
      "\u001b[1m\u001b[31m{R} \u001b[0m\u001b[1m--sim-cde-type, -C\u001b[0m\u001b[37m <text:including set={BCH|LDPC|POLAR|POLAR_MK|RA|REP|RS|RSC|RSC_DB|TPC|TURBO|TURBO_DB|UNCODED}>\u001b[0m\n",
      "      Select the channel code family to simulate. \n",
      "    \u001b[1m--sim-prec, -p    \u001b[0m\u001b[37m <integer:including set={8|16|32|64}>\u001b[0m\n",
      "      Specify the representation of the real numbers in the receiver part of the \n",
      "      chain. \n",
      "    \u001b[1m--sim-type        \u001b[0m\u001b[37m <text:including set={BFER|BFERI}>\u001b[0m\n",
      "      Select the type of simulation (or communication chain skeleton). \n",
      "\n",
      "\u001b[1m\u001b[3m\u001b[35mOther parameter(s):\u001b[0m\n",
      "    \u001b[1m--Help, -H        \u001b[0m\n",
      "      Print the help like with the '--help, -h' parameter plus advanced \n",
      "      arguments (denoted as '{A}'). \n",
      "    \u001b[1m--help, -h        \u001b[0m\n",
      "      Print the help with all the required (denoted as '{R}') and optional \n",
      "      arguments. The latter change depending on the selected simulation type and \n",
      "      code. \n",
      "    \u001b[1m--no-colors       \u001b[0m\n",
      "      Disable the colors in the shell. \n",
      "    \u001b[1m--version, -v     \u001b[0m\n",
      "      Print informations about the version of the source code and compilation \n",
      "      options. \n",
      "\n",
      "\u001b[1m\u001b[31m(EE) \u001b[0mThe \"--sim-cde-type, -C\" argument is required.\n"
     ]
    }
   ],
   "source": [
    "# !aff3ct\n",
    "!aff3ct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the RL Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "            0.0020 ||   366142 |    14959 |     9523 | 4.98e-04 | 2.60e-02 ||   59.999 | 00h00'00  *\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "from global_params import params\n",
    "from scoring import score_dataset\n",
    "from CPC import cpc_code, generate_random as gen_random_cpc\n",
    "\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Some quick thoughts:\n",
    "-- Should we start with a specific code each time or always a new random code?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SwapLDPCEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, target_succ_rate=0.99):\n",
    "        super(SwapLDPCEnv, self).__init__()\n",
    "\n",
    "        self.target_succ_rate = target_succ_rate\n",
    "        _, m_b, m_p, m_c = gen_random_cpc.random_cpc()\n",
    "        self.m_b = m_b\n",
    "        self.m_p = m_p\n",
    "        self.m_c = m_c\n",
    "        # self.target_succ_rate = target_succ_rate\n",
    "        # Each action corresponds to choosing to parity checks and the corresponding edges to swap\n",
    "        self.action_space = spaces.MultiDiscrete([\n",
    "            3,  # select which matrix to operate on, m_b, m_p, or m_c\n",
    "            # select which parity check to operate on\n",
    "            params['n_data_qubits'],\n",
    "            # higher than the check qubit index return a low reward\n",
    "            params['n_check_qubits'],\n",
    "            # select which data qubit to operate on. If m_c is selected, have choosing a data qubit\n",
    "        ])\n",
    "        self.last_fer = 0\n",
    "        self.n_steps = 0\n",
    "\n",
    "        self.n_qubits = n_qubits = params['n_data_qubits'] + \\\n",
    "            params['n_check_qubits']\n",
    "        flattened_pc_size = 2 * \\\n",
    "            (n_qubits) * \\\n",
    "            params['n_check_qubits']\n",
    "\n",
    "        # The first n qubits represent the noise distribution\n",
    "        # TODO: THIS ALLOWS US TO TRAIN FOR \"ADAPTIVE NOISE!!\" (i.e. lets decrease connections...)\n",
    "        # The quantum parity check matrix\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0,\n",
    "                                            shape=(n_qubits + flattened_pc_size,), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        p_fails = np.ones(self.n_qubits) * np.random.uniform(\n",
    "            low=params['constant_error_rate_lower'], high=params['constant_error_rate_upper'])\n",
    "        if action[0] == 0:\n",
    "            self.m_b[action[1], action[2]] = 1 - self.m_b[action[1], action[2]]\n",
    "        elif action[0] == 1:\n",
    "            self.m_p[action[1], action[2]] = 1 - self.m_p[action[1], action[2]]\n",
    "        elif action[0] == 2:\n",
    "            if action[1] >= params['n_check_qubits']:\n",
    "                old_code_pc = cpc_code.get_classical_code_cpc(\n",
    "                    self.m_b, self.m_p, self.m_c)\n",
    "                flattened = np.array(old_code_pc).astype(np.float32).flatten()\n",
    "                obs = np.concatenate((p_fails, flattened)).astype(np.float32)\n",
    "                return obs, -1, False, {}  # Return a very low reward\n",
    "            self.m_c[action[1], action[2]] = 1 - self.m_c[action[1], action[2]]\n",
    "        else:\n",
    "            raise \"Undefined selector action\"\n",
    "\n",
    "        code_pc = cpc_code.get_classical_code_cpc(self.m_b, self.m_p, self.m_c)\n",
    "        # TODO: p_fail??\n",
    "        succ_rate = score_dataset.run_decoder(code_pc, p_fails)\n",
    "\n",
    "        self.last_fer = 1 - succ_rate\n",
    "\n",
    "        # TODO: scaling?\n",
    "        reward = succ_rate\n",
    "        flattened = np.array(code_pc).astype(np.float32).flatten()\n",
    "        obs = np.concatenate((p_fails, flattened)).astype(np.float32)\n",
    "\n",
    "\t\t# Update global parameters\n",
    "        self.n_steps += 1\n",
    "\n",
    "        return obs, reward, succ_rate >= self.target_succ_rate, {}\n",
    "\n",
    "    def reset(self):\n",
    "        p_fails = np.ones(self.n_qubits) * np.random.uniform(\n",
    "            low=params['constant_error_rate_lower'], high=params['constant_error_rate_upper'])\n",
    "        _, m_b, m_p, m_c = gen_random_cpc.random_cpc()\n",
    "        self.m_b = m_b\n",
    "        self.m_p = m_p\n",
    "        self.m_c = m_c\n",
    "        code_pc = cpc_code.get_classical_code_cpc(self.m_b, self.m_p, self.m_c)\n",
    "        # reward, done, info can't be included\n",
    "        npd = np.array(code_pc).astype(np.float32)\n",
    "        return np.concatenate((p_fails, npd.flatten())).astype(np.float32)\n",
    "\n",
    "    def render(self, mode='console'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "env = SwapLDPCEnv()\n",
    "check_env(env, warn=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "            0.0020 ||   432476 |    13514 |     8680 | 3.81e-04 | 2.01e-02 ||   70.875 | 00h00'00  *\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "OS: Linux-5.15.0-58-generic-x86_64-with-glibc2.35 #64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023\n",
      "Python: 3.10.6\n",
      "Stable-Baselines3: 1.6.2\n",
      "PyTorch: 1.13.0+cu117\n",
      "GPU Enabled: False\n",
      "Numpy: 1.23.5\n",
      "Gym: 0.21.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "OS: Linux-5.15.0-58-generic-x86_64-with-glibc2.35 #64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023\n",
      "Python: 3.10.6\n",
      "Stable-Baselines3: 1.6.2\n",
      "PyTorch: 1.13.0+cu117\n",
      "GPU Enabled: False\n",
      "Numpy: 1.23.5\n",
      "Gym: 0.21.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "            0.0020 ||   418640 |    15414 |     9810 | 4.49e-04 | 2.34e-02 ||   68.609 | 00h00'00  *\r"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "env = SwapLDPCEnv() \n",
    "model_type = \"PPO\"\n",
    "check_env(env, warn=True)\n",
    "tf_logs = \"./logs/{model_type}-tensorboard\"\n",
    "\n",
    "# wrap it\n",
    "env = make_vec_env(lambda: env,   n_envs=1)\n",
    "\n",
    "loading_saved = True\n",
    "\n",
    "model = None\n",
    "if not loading_saved:\n",
    "\tmodel = PPO(\"MlpPolicy\", env=env, tensorboard_log=tf_logs)\n",
    "else:\n",
    "\t# TODO!\n",
    "\tmodel = PPO.load(utils.get_most_recent_model_path_rl(), env=env, print_system_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 03:41:24.961713: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-10 03:41:26.381138: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-02-10 03:41:26.381327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-02-10 03:41:26.381336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-10 03:41:27.101187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-02-10 03:41:27.101661: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-10 03:41:27.101691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lev-ThinkPad-P14s-Gen-1): /proc/driver/nvidia/version does not exist\n",
      "2023-02-10 03:41:27.102074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## Setup the callbacks\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList, BaseCallback\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting additional values in tensorboard.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        self.is_tb_set = False\n",
    "        super(TensorboardCallback, self).__init__(verbose)\n",
    "        writer = tf.summary.create_file_writer(tf_logs) ## TODO?\n",
    "        self.writer = writer\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Log additional tensor\n",
    "        # if not self.is_tb_set:\n",
    "        #     with self.model.graph.as_default():\n",
    "        #         tf.summary.scalar('value_target', tf.reduce_mean(self.model.value_target))\n",
    "        #         self.model.summary = tf.summary.merge_all()\n",
    "        #     self.is_tb_set = True\n",
    "\n",
    "        # Log scalar value (here a random variable)\n",
    "        env = self.model.get_env().envs[0]\n",
    "        fer = env.last_fer\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar('Frame Error Rate', fer, step=env.n_steps)\n",
    "            self.writer.flush()\n",
    "        return True\n",
    "\n",
    "\n",
    "# From https://stable-baselines.readthedocs.io/en/master/guide/examples.html\n",
    "class SaveModelOnTraining(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super(SaveModelOnTraining, self).__init__(verbose)\n",
    "        self.check_freq = params['rl_save_model_freq']\n",
    "        self.save_path = utils.get_most_recent_model_path_rl()\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "          \n",
    "          self.model.save(self.save_path)\n",
    "          print(\"Saving new model to {} for step {}\".format(self.save_path), self.n_calls)\n",
    "          with open(utils.get_most_recent_model_path_rl_info(), 'w') as f:\n",
    "            data = {\n",
    "              \"n_steps\": self.n_calls,\n",
    "              # \"last_fer\": \n",
    "            }\n",
    "            json.dump(data, f)\n",
    "        return True\n",
    "\n",
    "\n",
    "callback_list = CallbackList([TensorboardCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(WW) Found in Alist file connections of degree 0!916 | 6.93e-04 | 3.34e-02 ||   48.710 | 00h00'00  *\n",
      "(WW) Found in Alist file connections of degree 0!447 | 8.91e-04 | 3.28e-02 ||   42.242 | 00h00'00  *\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!757 | 4.79e-04 | 2.57e-02 ||   62.178 | 00h00'00  *\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!222 | 1.12e-03 | 6.52e-02 ||    8.078 | 00h00'01  *\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "(WW) Found in Alist file connections of degree 0!\n",
      "            0.0020 ||    79192 |     9287 |     6792 | 1.43e-03 | 8.58e-02 ||   12.981 | 00h00'00  *\r"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "\tmodel.learn(total_timesteps=100_000, callback=callback_list)\n",
    "\tmodel.save(utils.get_most_recent_model_path_rl())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
