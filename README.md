# AI_QEC

> Note: this repository is a work in progress. Please reach out to me on [Twitter](https://twitter.com/StamblerLev) or Telegram (my handle is @levstamb) for inquiries.

AI QEC attempts to find small LDPC codes (on the order of ~100 qubits when including parity check and data qubits) which can account for any error model.

## Overview
This repo uses a variant of a genetic algorithm in combination with deep learning (transformers) to learn LDPC quantum codes adapted to different noise models and decoders.
Essentially, a `scoring` transformer-based model is first trained to estimate the word error rate for a specific quantum parity check matrix and Pauli error noise model.
The `scoring` model takes a dense representation of a parity check matrix as well as the error rate on every qubit and attempts to output an estimated average word error rate.
The model is trained on data generated by simulating random quantum codes and their decoding.

Then, we use a `generating` model to create a new class of quantum codes. The generating model starts with random CPC LDPC codes and then uses the scoring model
to "tweak" the starting codes. Tweaking is done by running gradient descent on the scoring model where the output is 0 word error rate and the input is
the starting code and desired error range for which to optimize.

This entire process can be repeated for a few epochs like so:

1. Train a `scoring` model by using the `generating` model to create a class of codes and adding random mutations. If there is no generating model yet, train the scoring model on random CPC codes
2. Update the generating model with the new scoring model and go back to step 1.

Thus, we can have a few epochs of `looking for imporvements` in potential CPC codes.

### Moral Intuition
What is the reasing behing this project? Recent results have shown that transformers are able to "reason" about their input in predicting an output.
Thus, the hope is that the scoring model can learn what makes a code "good" when attempting to estimate the word error rates. Then, we take a greedy approach.
Essentially, the algorithm optimize a codes based off of structures the scoring model has already learned. The algorithm then introduces mutations with the hopes of getting the scoring
model to learn further structures which create good codes. 

## Using the repository
### Installation
First, install [aff3ct](https://github.com/aff3ct/aff3ct). aff3ct is used to simulate the different codes.
Please use their documentation for up to date installation instructions.

Then, install Stim
```
pip install stim
```